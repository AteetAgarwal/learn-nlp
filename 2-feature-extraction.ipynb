{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0508131",
   "metadata": {},
   "source": [
    "# Feature-extraction summary (pointer form)\n",
    "\n",
    "- Bag of Words (Count-based)\n",
    "    - What: Represents each document as counts of vocabulary terms (term-frequency).\n",
    "    - How in this notebook: `cv = CountVectorizer()` → `bow = cv.fit_transform(df['text']).toarray()`; current `bow` is a 4×13 integer matrix of counts.\n",
    "    - Pros: Simple, interpretable, fast; works well for many baseline models.\n",
    "    - Cons: Loses word order/context, high dimensional and sparse, raw counts not normalized.\n",
    "    - Tip: Use `CountVectorizer(binary=True)` for pure presence/absence (one-hot style per feature) or normalize/scale counts before some models.\n",
    "\n",
    "- One‑Hot Encoding (binary presence)\n",
    "    - What: Each vocabulary term becomes a binary feature (1 if appears in document, else 0).\n",
    "    - How to get it here: `CountVectorizer(binary=True)` or convert counts: `(bow > 0).astype(int)`.\n",
    "    - Pros: Removes document-length bias, simple for presence-based signals.\n",
    "    - Cons: Still sparse/high-dimensional; ignores frequency and context.\n",
    "\n",
    "- N‑grams (capture local order)\n",
    "    - What: Extend tokens to contiguous sequences of length n (bigrams, trigrams, etc.) to encode short-term word order.\n",
    "    - How in this notebook: `CountVectorizer(ngram_range=(2,2))` for bigrams, `ngram_range=(1,2)` for unigrams + bigrams (current `cv = CountVectorizer(ngram_range=(1, 2))`).\n",
    "    - Pros: Captures local phrases and context (e.g., \"write comment\"), improves performance when phrase meaning matters.\n",
    "    - Cons: Sharp increase in dimensionality and sparsity as n and corpus size grow; may need feature selection or hashing.\n",
    "\n",
    "- TF‑IDF (term-frequency × inverse-document-frequency)\n",
    "    - What: Weights terms by frequency in a doc and rarity across corpus: downweights common words and upweights discriminative ones.\n",
    "    - How in this notebook: `TfidfVectorizer()` → `tfidf.fit_transform(df['text']).toarray()`; `tfidf.idf_` gives inverse-document frequencies.\n",
    "    - Pros: Often better for classification/IR than raw counts; reduces impact of common tokens and normalizes document length.\n",
    "    - Cons: Still sparse and high-dimensional; may reduce useful signal for very short docs if idf unstable.\n",
    "\n",
    "- Practical guidance / trade-offs\n",
    "    - Start with TF‑IDF (unigrams) for classification problems; add n‑grams if phrases are important.\n",
    "    - Use binary features (one‑hot) if presence matters more than frequency.\n",
    "    - Apply dimensionality reduction / feature selection (chi2, mutual info, TruncatedSVD) or hashing for large vocabularies.\n",
    "    - Always inspect `cv.vocabulary_`, feature matrix shape, and sparsity before modeling; tune `ngram_range`, `min_df`, `max_df`, and stop-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f357baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36d0bc9",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fbe7717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"text\":[\"people watch campusx\", \"campusx watch campusx\", \"people write comment\", \"campusx write comment\"], \"output\":[1,1,0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e51bea22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95f68aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48ccd0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 2, 'with': 4, 'campusx': 0, 'watch': 3, 'write': 5, 'comment': 1}\n"
     ]
    }
   ],
   "source": [
    "bow = cv.fit_transform(df['text']).toarray()\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9048c551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 1 0]\n",
      " [2 0 0 1 0 0]\n",
      " [0 1 1 0 0 1]\n",
      " [1 1 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b954308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb4d080a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform([\"campusx watch and write comments of campusx\"]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122234e1",
   "metadata": {},
   "source": [
    "# Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "371f12da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a717c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people with': 2, 'with campusx': 5, 'campusx watch': 0, 'watch campusx': 4, 'people write': 3, 'write comment': 6, 'campusx write': 1}\n"
     ]
    }
   ],
   "source": [
    "bow = cv.fit_transform(df['text']).toarray()\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34859810",
   "metadata": {},
   "source": [
    "# Bigram + Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cbdf85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9e47952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 4, 'with': 9, 'campusx': 0, 'people with': 5, 'with campusx': 10, 'watch': 7, 'campusx watch': 1, 'watch campusx': 8, 'write': 11, 'comment': 3, 'people write': 6, 'write comment': 12, 'campusx write': 2}\n"
     ]
    }
   ],
   "source": [
    "bow = cv.fit_transform(df['text']).toarray()\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa7f29f",
   "metadata": {},
   "source": [
    "# TF / IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "270224fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44809973, 0.        , 0.55349232, 0.        , 0.70203482,\n",
       "        0.        ],\n",
       "       [0.78722298, 0.        , 0.        , 0.61666846, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.57735027, 0.57735027, 0.        , 0.        ,\n",
       "        0.57735027],\n",
       "       [0.49681612, 0.61366674, 0.        , 0.        , 0.        ,\n",
       "        0.61366674]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()\n",
    "tfidf.fit_transform(df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41070e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 2, 'with': 4, 'campusx': 0, 'watch': 3, 'write': 5, 'comment': 1}\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1efdcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22314355 1.51082562 1.51082562 1.91629073 1.91629073 1.51082562]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44a8c43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['campusx' 'comment' 'people' 'watch' 'with' 'write']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e01980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
